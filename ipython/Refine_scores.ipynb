{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rake\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../data/survey_unilever.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_kp = 10\n",
    "min_char_length = 1\n",
    "max_words_length = 1\n",
    "min_keyword_frequency = 1\n",
    "headers='What is Healthy Skin?'\n",
    "groupby=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_kp = float(nb_kp)\n",
    "srv_raw = pd.ExcelFile(filename)\n",
    "srv = srv_raw.parse()\n",
    "\n",
    "if len(headers) == 0:\n",
    "    del srv[list(srv)[0]]\n",
    "    qst = list(srv)\n",
    "    qst = [str(q).split(\"\\n\")[0] for q in list(srv)]\n",
    "    srv.columns = qst\n",
    "else:\n",
    "    qst = headers.split('%')\n",
    "    cols = [q.strip('\\n') for q in srv.columns]\n",
    "    srv.columns = cols\n",
    "\n",
    "srv_concat = [reduce(lambda x,y: str(x)+'. '+str(y), srv[qst[k]]) for k in range(len(qst))]\n",
    "\n",
    "stop_words_path = \"SmartStoplist.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rake_object = rake.Rake(stop_words_path, int(min_char_length), int(max_words_length), int(min_keyword_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = srv_concat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rake' from 'rake.pyc'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_list = rake.split_sentences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_list = rake.spell_check(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def handle_neg(candidate):\n",
    "    \n",
    "    candidate = candidate.lower()\n",
    "    neg_items = ['not a lot of', 'not', 'no', 'non', 'not', 'nor', 'free of', 'not too', 'not to', 'clear of', 'free of']\n",
    "    for neg_item in neg_items:\n",
    "        candidate = candidate.replace(neg_item, 'no')\n",
    "\n",
    "    word_list = candidate.split(' ')\n",
    "    if '' in word_list:\n",
    "        word_list.remove('') \n",
    "        \n",
    "    to_remove = []\n",
    "    new_phrases = []\n",
    "    cpt=0\n",
    "    \n",
    "    while cpt < len(word_list):\n",
    "        \n",
    "        if word_list[cpt][-4:] == 'less':\n",
    "            new_phrases.append('no_'+word_list[cpt][:-4])\n",
    "            \n",
    "            to_remove += [word_list[cpt]]\n",
    "            cpt += 1\n",
    "            continue\n",
    "        \n",
    "        if cpt+1 < len(word_list):\n",
    "            if word_list[cpt+1] == 'free':\n",
    "                new_phrases.append('no_'+word_list[cpt])\n",
    "                \n",
    "                to_remove += [word_list[cpt], word_list[cpt+1]]\n",
    "                cpt += 2\n",
    "                continue\n",
    "\n",
    "        if word_list[cpt] == 'no' and cpt+2 < len(word_list):\n",
    "                                                \n",
    "            if word_list[cpt+2] == 'or' and cpt+4 < len(word_list):\n",
    "                if word_list[cpt+4] != 'or':\n",
    "                    new_phrases.append('no_'+word_list[cpt+1])\n",
    "                    new_phrases.append('no_'+word_list[cpt+3])\n",
    "                    \n",
    "                    to_remove += [word_list[cpt], word_list[cpt+1], word_list[cpt+2], word_list[cpt+3]]\n",
    "                    cpt += 4\n",
    "                    continue\n",
    "                    \n",
    "                else:\n",
    "                    new_phrases.append('no_'+word_list[cpt+1])\n",
    "                    new_phrases.append('no_'+word_list[cpt+3])\n",
    "                    new_phrases.append('no_'+word_list[cpt+5])\n",
    "                    \n",
    "                    to_remove += [word_list[cpt], word_list[cpt+1], word_list[cpt+2], word_list[cpt+3], word_list[cpt+4], word_list[cpt+5]]\n",
    "                    cpt += 6\n",
    "                    continue\n",
    "                    \n",
    "            elif word_list[cpt+2] == 'or' and cpt+4 >= len(word_list):\n",
    "                new_phrases.append('no_'+word_list[cpt+1])\n",
    "                new_phrases.append('no_'+word_list[cpt+3])\n",
    "                    \n",
    "                to_remove += [word_list[cpt], word_list[cpt+1], word_list[cpt+2], word_list[cpt+3]]\n",
    "                cpt += 4\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                new_phrases.append('no_'+word_list[cpt+1])\n",
    "                \n",
    "                to_remove += [word_list[cpt], word_list[cpt+1]]\n",
    "                cpt += 2\n",
    "                continue\n",
    "                \n",
    "        elif word_list[cpt] == 'no' and cpt+1 < len(word_list):\n",
    "            new_phrases.append('no_'+word_list[cpt+1])\n",
    "                \n",
    "            to_remove += [word_list[cpt], word_list[cpt+1]]\n",
    "            cpt += 2\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            cpt += 1\n",
    "            continue\n",
    "    \n",
    "    to_keep = [el for el in word_list if el not in to_remove]\n",
    "    new_candidate = to_keep + new_phrases\n",
    "    \n",
    "    return ' '.join(new_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def handle_neg_list(sentence_list):\n",
    "    sent_handle_neg = []\n",
    "    for candidate in sentence_list:\n",
    "        sent_handle_neg.append(handle_neg(candidate))\n",
    "    return sent_handle_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_list = handle_neg_list(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words_path = \"SmartStoplist.txt\"\n",
    "stop_words_pattern = rake.build_stop_word_regex(stop_words_path)\n",
    "phrase_list = rake.generate_candidate_keywords(sentence_list, stop_words_pattern, min_char_length, max_words_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_list, phrase_list_stem, track_stem = rake.stem_candidate_keywords(phrase_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_word_frequency(phraseList):\n",
    "    word_frequency = {}\n",
    "    for phrase in phraseList:\n",
    "        \n",
    "        word_list = rake.separate_words(phrase, 0)\n",
    "        for word in word_list:\n",
    "            word_frequency.setdefault(word, 0)\n",
    "            word_frequency[word] += 1\n",
    "\n",
    "    return word_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_frequency = calculate_word_frequency(phrase_list_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_candidate_keyword_scores(final_list, word_scores_stem, track_stem, min_keyword_frequency=1):\n",
    "    keyword_candidates = {}\n",
    "    for phrase in final_list:\n",
    "        phrase_stem = track_stem[phrase]\n",
    "        if min_keyword_frequency > 1:\n",
    "            if final_list.count(phrase) < min_keyword_frequency:\n",
    "                continue\n",
    "        keyword_candidates.setdefault(phrase, 0)\n",
    "        word_list = rake.separate_words(phrase_stem, 0)\n",
    "        candidate_score = 0\n",
    "        for word in word_list:\n",
    "            candidate_score += word_frequency[word]\n",
    "        keyword_candidates[phrase] = float(candidate_score) / len(word_list)\n",
    "    return keyword_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keyword_candidates = generate_candidate_keyword_scores(final_list, word_frequency, track_stem, min_keyword_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('skin', 138.0),\n",
       " ('soft', 76.0),\n",
       " ('smoothness', 75.0),\n",
       " ('moisturizers', 64.0),\n",
       " ('glows', 60.0),\n",
       " ('no_dry', 38.0),\n",
       " ('clear', 37.0),\n",
       " ('cleaned', 33.0),\n",
       " ('no_blemish', 28.0),\n",
       " ('hydrated', 28.0),\n",
       " ('dry', 26.0),\n",
       " ('radiant', 17.0),\n",
       " ('touch', 16.0),\n",
       " ('tone', 15.0),\n",
       " ('no_acne', 15.0),\n",
       " ('supple', 11.0),\n",
       " ('blemishes', 11.0),\n",
       " ('moist', 10.0),\n",
       " ('no_oily', 9.0),\n",
       " ('care', 8.0),\n",
       " ('no_wrinkled', 8.0),\n",
       " ('oily', 8.0),\n",
       " ('vibrant', 7.0),\n",
       " ('bright', 6.0),\n",
       " ('color', 6.0)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import six\n",
    "import operator\n",
    "sorted_keywords = sorted(six.iteritems(keyword_candidates), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_keywords[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
